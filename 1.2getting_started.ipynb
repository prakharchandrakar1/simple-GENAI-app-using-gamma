{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cb523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1347c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prakharchandrakar/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "## data ingesation- from the website we need to scrape data\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ec0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x32880f9a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://openai.com/index/gpt-5-2-for-science-and-math/\")\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1bbc8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://openai.com/index/gpt-5-2-for-science-and-math/', 'title': 'Advancing science and math with GPT-5.2 | OpenAI', 'description': 'GPT-5.2 is our strongest model yet for math and science work.', 'language': 'en-US'}, page_content='Advancing science and math with GPT-5.2 | OpenAISkip to main contentLog inSwitch toChatGPT(opens in a new window)Sora(opens in a new window)API Platform(opens in a new window)ResearchSafetyFor BusinessFor DevelopersChatGPTSoraStoriesCompanyNewsResearchBack to main menuResearch IndexResearch OverviewResearch ResidencyOpenAI for ScienceLatest AdvancementsGPT-5.2GPT-5.1Sora 2GPT-5OpenAI o3 and o4-miniGPT-4.5SafetyBack to main menuSafety ApproachSecurity & PrivacyFor BusinessBack to main menuBusiness OverviewSolutionsLearnStartupsChatGPT PricingAPI PricingContact SalesFor DevelopersBack to main menuAPI PlatformAPI PricingAgentsCodexOpen ModelsCommunity(opens in a new window)ChatGPTBack to main menuExplore ChatGPTBusinessEnterpriseEducationPricingDownloadSoraStoriesCompanyBack to main menuAbout UsOur CharterFoundationCareersBrand GuidelinesNewsLog inOpenAITable of contentsStronger performance where precision mattersLooking aheadDecember 11, 2025PublicationProductAdvancing science and math with GPT-5.2GPT‑5.2 is our strongest model yet for math and science work.Read the paper(opens in a new window)Loading…ShareOne of our hopes for strong AI is that it will accelerate scientific research for the benefit of everyone, helping researchers explore more ideas, test them faster, and turn discoveries into impact.\\xa0Over the past year, we’ve been working closely with scientists across math, physics, biology, and computer science to understand where AI can help—and where it still falls short. Last month, we published a paper\\u2060 that compiles early case studies across math, physics, biology, computer science, astronomy, and materials science in which GPT‑5 helped researchers showing how GPT‑5 has already begun contributing to real scientific work. With GPT‑5.2, we’re starting to see those gains become more consistent and more reliable.Stronger performance where precision mattersGPT‑5.2 Pro and GPT‑5.2 Thinking are our strongest models yet for scientific and mathematical work.Strong mathematical reasoning is a foundation for reliability in scientific and technical work. It enables models to follow multi-step logic, keep quantities consistent, and avoid subtle errors that can compound in real analyses—from simulations and statistics to forecasting and modeling. Improvements on benchmarks like FrontierMath reflect not a narrow skill, but stronger general reasoning and abstraction, capabilities that carry directly into scientific workflows such as coding, data analysis, and experimental design.These capabilities are also closely tied to progress toward general intelligence. A system that can reliably reason through abstraction, maintain consistency across long chains of thought, and generalize across domains is exhibiting traits that are foundational to AGI—not task-specific tricks, but broad, transferable reasoning skills that matter across science, engineering, and real-world decision-making.We believe GPT‑5.2 Pro and GPT‑5.2 Thinking are the world’s best models for assisting and accelerating scientists. On GPQA Diamond, a graduate-level Google-proof Q&A benchmark, GPT‑5.2 Pro achieves 93.2%, followed closely by GPT‑5.2 Thinking at 92.4%.In GPQA Diamond\\u2060(opens in a new window), models answer multiple choice questions about physics, chemistry, and biology. No tools were enabled and reasoning effort was set to maximum.On FrontierMath (Tier 1–3), an evaluation of expert-level mathematics, GPT‑5.2 Thinking set a new state of the art, solving 40.3% of problems.In FrontierMath\\u2060(opens in a new window), models solve expert-level mathematics problems. A Python tool was enabled and reasoning effort was set to maximum.Case studyGPT‑5.2 is not only strong at graduate-level science problems. We now regularly see our frontier models contributing solutions to previously unsolved—and increasingly subtle—questions in mathematics and the sciences.In this case study, we describe how GPT‑5.2 Pro helped resolve an open research problem in statistical learning theory, documented in a new paper, On Learning-Curve Monotonicity for Maximum Likelihood Estimators\\u2060(opens in a new window).The question (“If you collect more data, do your results reliably get better?”) shows up any time you fit a model from data. You can draw a learning curve that tracks average error as you add more examples. In the best case, the curve is monotone. More data means less error, every step of the way. That is the behavior people hope for, and often assume.But over the last few years, researchers have learned that this intuition can fail. A line of work kicked off by an open problem posed at the Conference on Learning Theory (COLT) in 2019 by Viering, Mey, and Loog showed that the answer is often no. Even very simple, well-behaved toy setups can have non-monotonic learning curves, where adding data increases expected error. That surprise triggered a wave of follow-up papers. They expanded the list of settings where these reversals happen and proposed increasingly elaborate methods designed to restore monotone behavior.Still, one of the most basic cases remained unresolved. What happens in the cleanest textbook situation, where the statistical model is actually correct and the data follow the familiar bell curve pattern, with a known mean but unknown standard deviation? Researchers already knew that small changes to this setup could break monotonic behavior. But the answer remained unknown in this core case.Our new paper demonstrates that in this clean setting, intuition prevails: learning is predictably improved by more data, rather than behaving in surprising or unstable ways. What makes this paper unusual is how the proof was obtained. The authors did not work out a strategy and then ask the model to fill in steps. They did not provide intermediate arguments or a proof outline. Instead, they asked GPT‑5.2 Pro to solve the open problem directly, and then carefully verified the proof, including review and validation by external subject-matter experts.The authors then asked simple follow-up questions to see how far the idea could go. GPT‑5.2 Pro extended the result beyond the original problem to higher dimensional settings and other common statistical models. Throughout, the human role stayed focused on verification and clear writing, rather than supplying mathematical scaffolding.Looking aheadThis result suggests a useful direction for how AI systems can support scientific research, particularly in domains with axiomatic theoretical foundations such as mathematics and theoretical computer science. In settings like these, frontier models can help explore proofs, test hypotheses, and identify connections that might otherwise take substantial human effort to uncover.At the same time, these systems are not independent researchers. Expert judgment, verification, and domain understanding remain essential. Even highly capable models can make mistakes or rely on unstated assumptions. But they can also produce detailed, structured arguments that merit careful human study and refinement. Making reliable progress with AI therefore depends on workflows that keep validation, transparency, and collaboration firmly in the loop.Viewed as a case study, this result illustrates an emerging mode of research practice. Models like GPT‑5.2 can serve as tools for supporting mathematical reasoning and accelerating early-stage exploration, while responsibility for correctness, interpretation, and context remains with human researchers. Used carefully, such systems may help streamline significant aspects of theoretical work without displacing the central role of human judgment in scientific inquiry.GPTReasonings & Policy2025AuthorOpenAIKeep readingView allEvaluating AI’s ability to perform scientific research tasksResearchDec 16, 2025Measuring AI’s capability to accelerate biological researchResearchDec 16, 2025The new ChatGPT Images is hereProductDec 16, 2025Our ResearchResearch IndexResearch OverviewResearch ResidencyOpenAI for ScienceLatest AdvancementsGPT-5OpenAI o3OpenAI o4-miniGPT-4oGPT-4o miniSoraSafetySafety ApproachSecurity & PrivacyTrust & TransparencyChatGPTExplore ChatGPT(opens in a new window)BusinessEnterpriseEducationPricing(opens in a new window)Download(opens in a new window)SoraSora OverviewFeaturesPricingSora log in(opens in a new window)API PlatformPlatform OverviewPricingAPI log in(opens in a new window)Documentation(opens in a new window)Developer Forum(opens in a new window)For BusinessBusiness OverviewSolutionsContact SalesCompanyAbout UsOur CharterFoundationCareersBrandSupportHelp Center(opens in a new window)MoreNewsStoriesLivestreamsPodcastRSSTerms & PoliciesTerms of UsePrivacy PolicyOther Policies (opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)OpenAI © 2015–2025Manage CookiesEnglishUnited States')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74098798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000 ,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bd911ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embadding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a1a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoredb= FAISS.from_documents(documents,embadding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d33d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x32a4fc940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eefd85a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UsOur CharterFoundationCareersBrand GuidelinesNewsLog inOpenAITable of contentsStronger performance where precision mattersLooking aheadDecember 11, 2025PublicationProductAdvancing science and math with GPT-5.2GPT‑5.2 is our strongest model yet for math and science work.Read the paper(opens in a new window)Loading…ShareOne of our hopes for strong AI is that it will accelerate scientific research for the benefit of everyone, helping researchers explore more ideas, test them faster, and turn discoveries into impact.\\xa0Over the past year, we’ve been working closely with scientists across math, physics, biology, and computer science to understand where AI can help—and where it still falls short. Last month, we published a paper\\u2060 that compiles early case studies across math, physics, biology, computer science, astronomy, and materials science in which GPT‑5 helped researchers showing how GPT‑5 has already begun contributing to real scientific work. With GPT‑5.2, we’re starting to see those'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### quary from vector store db\n",
    "query = \"Stronger performance where precision matters\"\n",
    "result = vectorstoredb.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cd0f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dfc5b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n\\n<context>   \\n{context}\\n</context>\\n\\nQuestion: {question}\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x32880eec0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x32a4fe5c0>, root_client=<openai.OpenAI object at 0x329e4f490>, root_async_client=<openai.AsyncOpenAI object at 0x32a4fcdf0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Answer the following question based only on the provided context:\n",
    "\n",
    "<context>   \n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "document_chain = prompt | llm | StrOutputParser()\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b10d807c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The document's content suggests that there is a focus on enhancing or improving performance in areas or situations where precision is a critical factor. This likely means that the document discusses improvements or strategies for achieving better results in tasks or fields where accuracy and careful attention to detail are essential.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"question\": \"Stronger performance where precision matters\",\n",
    "    \"context\": [\n",
    "        Document(page_content=\"Stronger performance where precision matters\")\n",
    "    ]\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "413a3df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-5.2 demonstrates stronger performance where precision is critical, particularly in math and science work. It is essential for models to have strong mathematical reasoning to ensure reliability in scientific and technical work. This allows the model to follow multi-step logic, maintain consistency in quantities, and avoid subtle errors that can occur in real analyses, such as simulations, statistics, forecasting, and modeling. Improvements observed in benchmarks like FrontierMath indicate not just a specific skill but stronger general reasoning and abstraction, which are crucial for scientific workflows, including coding, data analysis, and experimental design. These characteristics contribute to progress toward general intelligence by providing broad, transferable reasoning skills necessary across various domains in science, engineering, and real-world decision-making.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# document chain\n",
    "document_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# retriever\n",
    "retriever = vectorstoredb.as_retriever()\n",
    "\n",
    "# FIXED retrieval chain\n",
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | document_chain\n",
    ")\n",
    "\n",
    "response = retrieval_chain.invoke({\n",
    "    \"question\": \"Stronger performance where precision matters\"\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "424cb36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context outlines that GPT-5.2, particularly through its Pro and Thinking variants, excels in situations where precision is crucial. This enhanced precision is supported by strong mathematical reasoning, enabling the models to maintain consistency, accurately follow multi-step logic, and avoid errors in analyses like simulations, statistics, forecasting, and modeling. Furthermore, improvements in benchmarks such as FrontierMath indicate that these capabilities reflect stronger general reasoning and abstraction skills, which are directly applicable to scientific workflows like coding, data analysis, and experimental design. These qualities also contribute to progress toward general intelligence, as the models exhibit broad, transferable reasoning skills essential for scientific, engineering, and real-world decision-making.\n"
     ]
    }
   ],
   "source": [
    "## Get the response form the LLM\n",
    "response=retrieval_chain.invoke({\"question\":\"Stronger performance where precision matters\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bfe35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ebc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76a9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25dc83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc93d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb68b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08643586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a746d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb402e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e5197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b5a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faa1955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b94ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rnn_env)",
   "language": "python",
   "name": "rnn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
